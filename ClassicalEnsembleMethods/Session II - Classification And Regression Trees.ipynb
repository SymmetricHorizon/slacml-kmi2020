{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                       Outline\n",
    "\n",
    "## Section 1: Decision Trees\n",
    "#### Section 1.1 Intuition Underlying Tree Based Models\n",
    "#### Section 1.2 Applying Tree Based Models\n",
    "#### Section 1.3 Shortcomings & Limitations\n",
    "\n",
    "## Section 2: Ensemble Methods & Random Forests\n",
    "#### Section 2.1 Intuition underlying ensemble approaches\n",
    "#### Section 2.2 Toy Classification Example\n",
    "#### Section 2.3 Time series Regression Example\n",
    "#### Section 2.4 MNIST Dataset Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1 Intuition Underlying Tree Based Models\n",
    "### I Spy With My Little Eye...\n",
    "There is a popular game played by children, during road trips, called \"I Spy With My Little Eye\". It involves one person choosing something they saw and the other has to infer said something based on a series of yes/no questions.\n",
    "![alt text](Errata/Fig1.pdf \"I Spy With My Little Eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this game, the player partitions the space of total possible objects, with each question defining a new split, till there's just one member left in the accessible space.\n",
    "\n",
    "For instance, the first question takes away the inanimate objects in the space.\n",
    "![alt text](Errata/Fig2b.pdf \"I Spy With My Little Eye\")\n",
    "\n",
    "The second question removes the 4-legged friends from the picture.\n",
    "![alt text](Errata/Fig2c.pdf \"I Spy With My Little Eye\")\n",
    "\n",
    "The final question removes the terrestrial creatures, in favor of our feathered friends.\n",
    "![alt text](Errata/Fig2d.pdf \"I Spy With My Little Eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematical parlance, the little girl is solving a multi-class classification problem using disjoint partitions on the space of measurable events using directed acyclic graphs. Used thus, these DAGs are Classification And Regression Trees.\n",
    "![alt text](Errata/Fig3a.pdf \"I Spy With My Little Eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification & Regression Trees (CARTs) are non-parametric models, that learn such \"splits\" on the feature space from data, to define a mapping from different partitions of the feature space to values on the target space.\n",
    "![alt text](Errata/Fig4.pdf \"I Spy With My Little Eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.2 Applying Tree Based Models\n",
    "In this section, we apply tree based models to datasets and analyze their performance to visualize their strangths and weaknesses. But first, we start off by generating some data for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=300, centers=4,random_state=0, cluster_std=1)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='gist_rainbow')\n",
    "plt.xlabel(\"$X_1$\")\n",
    "plt.ylabel(\"$X_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last code cell, first we instantiate the decision tree model (\"tree = DecisionTreeClassifier(max_depth=3)\"). \n",
    "The second step is fitting the model basde on the data. The process of fitting involves evaluating between a series of splits of the feature space and choosing the best at each step via a greedy approach.\n",
    "\n",
    "A tree defines a partition on the space, and every node of the tree defines a split of the dataset. The tree is a sequence of splits, chosen based on the data. At every step, possible splits are evaluated based on increase in homogeneity of data due to the split.\n",
    "\n",
    "![alt text](Errata/Fig5.pdf \"I Spy With My Little Eye\")\n",
    "\n",
    "There are various arguments that can be passed to the classifier during instantiation. The primary ones include:\n",
    "\n",
    "a) max_depth=n,  This determines the number of splits in the tree. \n",
    "\n",
    "b) criterion=\"gini\" or \"entropy\", This determines the criterion used to evaluate the split. \n",
    "etc.\n",
    "\n",
    "\n",
    "We shall experiment over the maximum depth criterion, later. For the moment, let's keep that fixed at 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap='gist_rainbow',clim=(y.min(), y.max()), zorder=3)\n",
    "xx, yy = np.meshgrid(np.linspace(np.min(X[:,0]),np.max(X[:,0]), num=200),np.linspace(np.min(X[:,1]),np.max(X[:,1]), num=200))\n",
    "Z = tree.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "n_classes = len(np.unique(y))\n",
    "contours = plt.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap='gist_rainbow', zorder=1)\n",
    "#plt.savefig('Fig6f.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we vary the maximum depth of the tree from 3 to 6 to 10. As we see in the ensuing figures, the tree's predictions improve a tad, but then quickly devolve to overfitting.\n",
    "![alt text](Fig6a3.pdf \"I Spy With My Little Eye\")\n",
    "![alt text](Fig6c5.pdf \"I Spy With My Little Eye\")\n",
    "![alt text](Fig6e10.pdf \"I Spy With My Little Eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solved Exercise: Classification on the Pima Indian Diabetes Dataset\n",
    "\n",
    "Diabetes is a condition where the body develops a resistance to insulin. The PIMA Indians of Arizona have been studied for decades and we found that they were extremely prone to adult onset diabetes. In essence, the tribe changed its dietary habits (to modern processed foods). For some stange reason, this caused them to have the highest incidence of diabetes in the entire country.\n",
    "\n",
    "Here, we'll go through a dataset released by the government, where almost 800 tribe members from Arizona were tested. We measured their blood glucose, their Blood pressures etc...and their diabetes state. Let's see if we can use this data, with a DecisionTree model to create a classifier to predict if a tibesperson has diabetes based on their vitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['Pregnancy','Glucose','BP','Skin','Insulin','BMI','Pedigree','Age','Label']\n",
    "pima=pd.read_csv(\"Errata/pima-indians-diabetes.csv\",header=None,names=colnames)\n",
    "pima.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names=['Pregnancy','Glucose','BP','Skin','Insulin','BMI','Pedigree','Age']\n",
    "X=pima[feature_column_names]\n",
    "y=pima.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision Tree Classifier Accuracy:\", metrics.accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.6)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, train_size=0.5)\n",
    "\n",
    "X_train.shape,X_val.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=[]\n",
    "\n",
    "for i in range(15):\n",
    "    clf=DecisionTreeClassifier(max_depth=i+1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    ytemp=clf.predict(X_val)\n",
    "    e.append(metrics.accuracy_score(y_val,ytemp))\n",
    "    \n",
    "plt.plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
