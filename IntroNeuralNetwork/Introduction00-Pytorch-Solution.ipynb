{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch: Warm-up\n",
    "\n",
    "We hope you have had time to look at the [Prerequisites/Python-05-PyTorch](https://github.com/drinkingkazu/slacml-kmi2020/blob/master/Prerequisites/Python-05-PyTorch.ipynb) example to learn about `Pytorch`, a neural network library we use in this workshop. This notebook is to revisit the similar contents to ensure we cover the basics before playing with more complicated examples. In fact, we will simply make the same contents into exercises :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "SEED=123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - data types\n",
    "\n",
    "1. Create a `torch.Tensor` of a shape (3,2) filled with zeros, ones, and also random values sampled from a normal distribution (0 mean 1 std).\n",
    "2. Create a `torch.Tensor` of a shape (10,10) filled with zeros except for the diagonal elements with ones. Compute the mean and std of the elements.\n",
    "3. Reshape the tensor from step 2 into (1,1,10,10)\n",
    "4. Repeat the step 2 to compute the mean and std, but use 8 byte (64 bit, double precision) floating point.\n",
    "5. Slice the diagonal element of the 2D tensor from step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.zeros:\n",
      " tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "\n",
      "torch.ones:\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "\n",
      "torch.randn:\n",
      " tensor([[-0.1115,  0.1204],\n",
      "        [-0.3696, -0.2404],\n",
      "        [-1.1969,  0.2093]])\n",
      "\n",
      "identity matrix:\n",
      " tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "\n",
      "mean 0.10000000149011612 std 0.30151134729385376\n",
      "\n",
      "Reshaped torch.Size([1, 1, 10, 10])\n",
      "\n",
      "64 bit mean 0.1 std 0.3015113445777634\n",
      "\n",
      "The diagonal slice tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Step 1 ... Tensor of 0s = numpy.zeros\n",
    "t=torch.zeros(3,2)\n",
    "print('torch.zeros:\\n',t)\n",
    "\n",
    "# Step 1 ... Tensor of 1s = numpy.ones\n",
    "t=torch.ones(3,2)\n",
    "print('\\ntorch.ones:\\n',t)\n",
    "\n",
    "# Step 1 ... Normal distribution centered at 0.0 and sigma=1.0 = numpy.rand.randn\n",
    "t=torch.randn(3,2)\n",
    "print('\\ntorch.randn:\\n',t)\n",
    "\n",
    "# Step 2 ... Identity matrix\n",
    "t=torch.eye(10)\n",
    "print('\\nidentity matrix:\\n',t)\n",
    "print('\\nmean',t.mean().item(),'std',t.std().item())\n",
    "\n",
    "# Step 3 ... reshaping\n",
    "print('\\nReshaped',t.reshape(1,1,*tuple(t.shape)).shape)\n",
    "\n",
    "# Step 4 ... Double precision\n",
    "t=torch.eye(10,dtype=torch.float64)\n",
    "print('\\n64 bit mean',t.mean().item(),'std',t.std().item())\n",
    "\n",
    "# Step 5 ... Slicing\n",
    "print('\\nThe diagonal slice',t[t>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"dataloader\"></a>\n",
    "## Exercise 2 - dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._data = tuple(range(100))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self._data[index]\n",
    "    \n",
    "data = dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Construct a data loader with batch size 10 and enable random shuffling.\n",
    "2. Loop over 20 iterations. Print the batch data in each loop.\n",
    "3. After 10 iterations, was there any duplicate data entry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 batch data tensor([12, 22, 48, 77,  3, 65, 26, 47, 99, 43])\n",
      "Iteration 1 batch data tensor([89, 90, 25, 61, 20, 41, 52, 27,  0, 35])\n",
      "Iteration 2 batch data tensor([54, 67, 45, 78, 72,  1, 14, 83, 44, 80])\n",
      "Iteration 3 batch data tensor([ 9, 98, 24, 95, 70, 23, 69, 75, 29,  2])\n",
      "Iteration 4 batch data tensor([91, 55,  5, 71, 68, 38, 31, 92, 39,  4])\n",
      "Iteration 5 batch data tensor([74, 17, 94, 62, 79, 49,  7, 76, 15, 28])\n",
      "Iteration 6 batch data tensor([42, 10, 59, 86, 50, 16, 97, 57, 84, 63])\n",
      "Iteration 7 batch data tensor([96, 66, 18, 46, 13, 88, 40, 53, 33, 81])\n",
      "Iteration 8 batch data tensor([85, 36, 87, 58, 37, 11, 30, 73, 32, 93])\n",
      "Iteration 9 batch data tensor([21, 19, 34, 82,  8, 60, 56,  6, 51, 64])\n",
      "Iteration 10 batch data tensor([43, 96,  9, 21, 75, 99,  6, 81, 27, 31])\n",
      "Iteration 11 batch data tensor([65, 51, 34, 92,  0, 97, 66, 68, 53, 32])\n",
      "Iteration 12 batch data tensor([58, 57, 88, 12, 94, 29, 87, 19, 62, 48])\n",
      "Iteration 13 batch data tensor([30, 95, 85, 16, 91, 73, 41, 61, 79, 17])\n",
      "Iteration 14 batch data tensor([54, 77,  4, 50, 37, 39, 59, 35, 83, 22])\n",
      "Iteration 15 batch data tensor([42, 18, 72, 15, 23, 26, 90, 52, 11, 33])\n",
      "Iteration 16 batch data tensor([98, 74,  2, 14, 40, 76,  1, 28, 44, 46])\n",
      "Iteration 17 batch data tensor([13, 45, 67,  5, 80, 47, 70, 24, 89, 63])\n",
      "Iteration 18 batch data tensor([49, 71, 69, 55, 36, 60, 20,  8, 56, 93])\n",
      "Iteration 19 batch data tensor([38, 25, 64, 82,  3,  7, 78, 84, 86, 10])\n",
      "\n",
      "unique data element count: 100\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(data,batch_size=10,shuffle=True,num_workers=1)\n",
    "ctr = 0\n",
    "while ctr<20:\n",
    "    for batch_data in loader:\n",
    "        print('Iteration',ctr,'batch data',batch_data)\n",
    "        ctr += 1\n",
    "        \n",
    "# check data unique count after 10 iterations\n",
    "data_collection = []\n",
    "for batch_data in loader:\n",
    "    data_collection.append(batch_data.numpy())\n",
    "    \n",
    "print('\\nunique data element count:',len(np.unique(np.concatenate(data_collection))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"graph\"></a>\n",
    "## Exercise 3 - Pytorch `nn` modules\n",
    "\n",
    "In the prerequisites, you have seen a few `nn` modules. Let's review them:\n",
    "\n",
    "* `torch.nn.ReLU` ([link](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)) ... a function that takes an input tenor and outputs a tensor of the same shape where elements are 0 if the corresponding input element has a value below 0, and otherwise the same value.\n",
    "* `torch.nn.Softmax` ([link](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax)) ... a function that applies a [softmax function](https://en.wikipedia.org/wiki/Softmax_function) on the specified dimension of an input data.\n",
    "* `torch.nn.MaxPool2d` ([link](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)) ... a function that down-sample the input matrix by taking maximum value from sub-matrices of a specified shape.\n",
    "\n",
    "We introduce another module, a linear model\n",
    "* `torch.nn.Linear` ([link](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) ... a module that can implement multiple linear models (i.e. $\\vec{w}\\cdot\\vec{x}+b$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights Parameter containing:\n",
      "tensor([[-0.4078]], requires_grad=True)\n",
      "\n",
      "Bias Parameter containing:\n",
      "tensor([0.0331], requires_grad=True)\n",
      "\n",
      "With input (0) ... 0.033124566078186035\n",
      "\n",
      "With input (1) ... -0.37465155124664307\n",
      "\n",
      "With input (1,...1) [[-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
    "print('\\nWeights',model.weight)\n",
    "print('\\nBias',model.bias)\n",
    "\n",
    "# Try multiplying 0\n",
    "data = torch.Tensor([0.])\n",
    "print('\\nWith input (0) ...', model(data).item())\n",
    "\n",
    "# Try multiplying 1\n",
    "data = torch.Tensor([1.])\n",
    "print('\\nWith input (1) ...', model(data).item())\n",
    "\n",
    "# Try 10 input data points\n",
    "data = torch.Tensor([1.]*10).reshape(10,1)\n",
    "print('\\nWith input (1,...1)',model(data).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose we have 2 data points where each data point is represented by a 2D matrix of 5x6 filled with values sampled from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
       "         [-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
       "         [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
       "         [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
       "         [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255]],\n",
       "\n",
       "        [[-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
       "         [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
       "         [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
       "         [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
       "         [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor of shape (1,5,5) with some negative and positive values\n",
    "torch.manual_seed(123)\n",
    "data = torch.randn(60).reshape(2,5,6)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose we apply \n",
    "1. `ReLU`\n",
    "2. `Softmax` across `dim=2`\n",
    "3. `MaxPool2d` with `kernel_size=(1,3)`\n",
    "4. `flatten`\n",
    "\n",
    "* What is the shape of the output tensor?\n",
    "* Implement above operations.\n",
    "* Reshape the output of the last step so that it can be consumed by `Linear` module of `in_features=5` and `out_features=1`.\n",
    "* Write a torch module (class) that performs a simple operation of \"multiply 10\" to the input tensor.\n",
    "* Implement all modules into a `torch.nn.Sequential` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the output after flatten torch.Size([20])\n",
      "Linear layer output tensor([[0.0834],\n",
      "        [0.2547],\n",
      "        [0.2215],\n",
      "        [0.2266]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.8344],\n",
      "        [2.5468],\n",
      "        [2.2151],\n",
      "        [2.2662]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Implement steps 1 to 5\n",
    "op1 = torch.nn.ReLU()\n",
    "op2 = torch.nn.Softmax(dim=2)\n",
    "op3 = torch.nn.MaxPool2d(kernel_size=(1,3))\n",
    "\n",
    "flattened = torch.flatten(op3(op2(op1(data))))\n",
    "print('Shape of the output after flatten', flattened.shape)\n",
    "\n",
    "# We need to reshape so that the data has 5 features\n",
    "op4 = torch.nn.Linear(in_features=5,out_features=1)\n",
    "print('Linear layer output',op4(flattened.reshape(-1,5)))\n",
    "\n",
    "# module to multiply 10\n",
    "\n",
    "class MyOp(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self,linear_op):\n",
    "        super().__init__()\n",
    "        self.linear = linear_op\n",
    "        \n",
    "    def forward(self,data):\n",
    "        return self.linear(torch.flatten(data).reshape(-1,5)) * 10\n",
    "    \n",
    "op5 = MyOp(op4)\n",
    "op_all = torch.nn.Sequential(op1,op2,op3,op5)\n",
    "print(op_all(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
