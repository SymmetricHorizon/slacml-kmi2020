{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch: Warm-up\n",
    "\n",
    "We hope you have had time to look at the [Prerequisites/Python-05-PyTorch](https://github.com/drinkingkazu/slacml-kmi2020/blob/master/Prerequisites/Python-05-PyTorch.ipynb) example to learn about `Pytorch`, a neural network library we use in this workshop. This notebook is to revisit the similar contents to ensure we cover the basics before playing with more complicated examples. In fact, we will simply make the same contents into exercises :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "SEED=123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - data types\n",
    "\n",
    "1. Create a `torch.Tensor` of a shape (3,2) filled with zeros, ones, and also random values sampled from a normal distribution (0 mean 1 std).\n",
    "2. Create a `torch.Tensor` of a shape (10,10) filled with zeros except for the diagonal elements with ones. Compute the mean and std of the elements.\n",
    "3. Reshape the tensor from step 2 into (1,1,10,10)\n",
    "4. Repeat the step 2 to compute the mean and std, but use 8 byte (64 bit, double precision) floating point.\n",
    "5. Slice the diagonal element of the 2D tensor from step 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"dataloader\"></a>\n",
    "## Exercise 2 - dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._data = tuple(range(100))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self._data[index]\n",
    "    \n",
    "data = dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Construct a data loader with batch size 10 and enable random shuffling.\n",
    "2. Loop over 20 iterations. Print the batch data in each loop.\n",
    "3. After 10 iterations, was there any duplicate data entry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"graph\"></a>\n",
    "## Exercise 3 - Pytorch `nn` modules\n",
    "\n",
    "In the prerequisites, you have seen a few `nn` modules. Let's review them:\n",
    "\n",
    "* `torch.nn.ReLU` ([link](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)) ... a function that takes an input tenor and outputs a tensor of the same shape where elements are 0 if the corresponding input element has a value below 0, and otherwise the same value.\n",
    "* `torch.nn.Softmax` ([link](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax)) ... a function that applies a [softmax function](https://en.wikipedia.org/wiki/Softmax_function) on the specified dimension of an input data.\n",
    "* `torch.nn.MaxPool2d` ([link](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)) ... a function that down-sample the input matrix by taking maximum value from sub-matrices of a specified shape.\n",
    "\n",
    "We introduce another module, a linear model\n",
    "* `torch.nn.Linear` ([link](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) ... a module that can implement multiple linear models (i.e. $\\vec{w}\\cdot\\vec{x}+b$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights Parameter containing:\n",
      "tensor([[-0.4078]], requires_grad=True)\n",
      "\n",
      "Bias Parameter containing:\n",
      "tensor([0.0331], requires_grad=True)\n",
      "\n",
      "With input (0) ... 0.033124566078186035\n",
      "\n",
      "With input (1) ... -0.37465155124664307\n",
      "\n",
      "With input (1,...1) [[-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]\n",
      " [-0.37465155]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
    "print('\\nWeights',model.weight)\n",
    "print('\\nBias',model.bias)\n",
    "\n",
    "# Try multiplying 0\n",
    "data = torch.Tensor([0.])\n",
    "print('\\nWith input (0) ...', model(data).item())\n",
    "\n",
    "# Try multiplying 1\n",
    "data = torch.Tensor([1.])\n",
    "print('\\nWith input (1) ...', model(data).item())\n",
    "\n",
    "# Try 10 input data points\n",
    "data = torch.Tensor([1.]*10).reshape(10,1)\n",
    "print('\\nWith input (1,...1)',model(data).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose we have 2 data points where each data point is represented by a 2D matrix of 5x6 filled with values sampled from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
       "         [-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
       "         [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
       "         [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
       "         [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255]],\n",
       "\n",
       "        [[-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
       "         [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
       "         [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
       "         [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
       "         [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor of shape (1,5,5) with some negative and positive values\n",
    "torch.manual_seed(123)\n",
    "data = torch.randn(60).reshape(2,5,6)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose we apply \n",
    "1. `ReLU`\n",
    "2. `Softmax` across `dim=2`\n",
    "3. `MaxPool2d` with `kernel_size=(1,3)`\n",
    "4. `flatten`\n",
    "\n",
    "* What is the shape of the output tensor?\n",
    "* Implement above operations.\n",
    "* Reshape the output of the last step so that it can be consumed by `Linear` module of `in_features=5` and `out_features=1`.\n",
    "* Write a torch module (class) that performs a simple operation of \"multiply 10\" to the input tensor.\n",
    "* Implement all modules into a `torch.nn.Sequential` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
